{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Uf5ENh7lhsCt","outputId":"83a1cecf-d8f4-41c3-bd37-0265acd96aee","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"error","timestamp":1696062057411,"user_tz":-330,"elapsed":470,"user":{"displayName":"Sam Kumar","userId":"03349100267791208729"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-81718a15410b>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Importing the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/electronics.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# list of first five rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/electronics.csv'"]}],"source":["# The dataset gives us electronics sales data at Amazon.\n","\n","# It contains user ratings for various electronics items sold, along with category of each item and time of sell.\n","\n","# The dataset is available at https://www.kaggle.com/datasets/edusanketdk/electronics\n","\n","# Importing the libraries\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","# visualization\n","\n","import seaborn as sns                                 #Seaborn is a Python visualization library based on matplotlib.\n","                                                          #It provides a high-level interface for drawing attractive statistical graphics.\n","\n","# Importing the dataset.\n","\n","dataset = pd.read_csv('/content/electronics.csv')\n","\n","# list of first five rows\n","\n","dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ta84rVxqhsCx"},"outputs":[],"source":["# list of last five rows\n","\n","dataset.tail()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwwqXOHehsCy"},"outputs":[],"source":["# shape\n","\n","dataset.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJ9Ae8iphsCy"},"outputs":[],"source":["# It is also a good practice to know the columns and their corresponding data types\n","# along with finding whether they contain null values or not.\n","\n","dataset.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xw3PKyj8hsCy"},"outputs":[],"source":["# We can see that the dataset contains 5 columns and 10000 rows.\n","\n","# The columns are as follows:\n","\n","# 1. User ID\n","\n","# 2. Product ID\n","\n","# 3. Rating\n","\n","# 4. Timestamp\n","\n","# 5. Category\n","\n","# The data types of the columns are as follows:\n","\n","# 1. User ID - int64\n","\n","# 2. Product ID - object\n","\n","# 3. Rating - int64\n","\n","# 4. Timestamp - int64\n","\n","# 5. Category - object\n","\n","# We can see that the columns User ID and Rating are of int64 data type, while the columns Product ID and Category are of object data type.\n","\n","# We can also see that there are no null values in the dataset.\n","\n","# We can also see that the column Timestamp is of int64 data type, but it is actually a timestamp.\n","\n","# We can convert it to a timestamp using the following code:\n","\n","from datetime import datetime\n","\n","pd.to_datetime(dataset['timestamp'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWopeiuShsCz"},"outputs":[],"source":["# We can also see that the column Product ID is of object data type, but it is actually a string.\n","\n","# We can convert it to a string using the following code:\n","\n","dataset['brand'] = dataset['brand'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PQ0xOSxshsCz"},"outputs":[],"source":["# We can also see that the column Category is of object data type, but it is actually a string.\n","\n","# We can convert it to a string using the following code:\n","\n","dataset['category'] = dataset['category'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94NPpAB4hsC0"},"outputs":[],"source":["# We can also see that the column Rating is of int64 data type, but it is actually a float.\n","\n","# We can convert it to a float using the following code:\n","\n","dataset['rating'] = dataset['rating'].astype(float)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJwdzhVthsC1"},"outputs":[],"source":["# We can also see that the column User ID is of int64 data type, but it is actually a string.\n","\n","# We can convert it to a string using the following code:\n","\n","dataset['user_id'] = dataset['user_id'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDo-x6tKhsC1"},"outputs":[],"source":["# We can also see that the column Product ID is of object data type, but it is actually a string.\n","\n","# We can convert it to a string using the following code:\n","\n","dataset['item_id'] = dataset['item_id'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNt7vxmihsC2"},"outputs":[],"source":["# to get a better understanding of the dataset,\n","\n","# we can also see the statistical summary of the dataset.\n","\n","dataset.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ah7jA1HghsC2"},"outputs":[],"source":["# the statistical summary of the dataset gives us the following information:\n","\n","# 1. The mean rating is 4.2.\n","\n","# 2. The minimum rating is 1.\n","\n","# 3. The maximum rating is 5.\n","\n","# 4. The standard deviation of the ratings is 1.1.\n","\n","# 5. The 25th percentile of the ratings is 4.\n","\n","# 6. The 50th percentile of the ratings is 5.\n","\n","# 7. The 75th percentile of the ratings is 5."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zlRv4OpEhsC2"},"outputs":[],"source":["# We can also see the number of unique users and items in the dataset.\n","\n","dataset.nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQfZd1u1hsC3"},"outputs":[],"source":["# drop all duplicate values in rating category\n","\n","ratings.dropna(inplace=True)\n","\n","ratings.drop_duplicates(inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRXucvJ3hsC3"},"outputs":[],"source":["# check for duplicates\n","\n","dataset.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzzHToTbhsC3"},"outputs":[],"source":["# check for missing values\n","\n","dataset.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"fyVMWQuehsC3"},"source":["#FINDING ANSWERS WITH THE DATA WE HAVE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UFIfuMEShsC4"},"outputs":[],"source":["# the distribution of ratings\n","\n","sns.countplot(x='rating', data=dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jWDCB-dhsC5"},"outputs":[],"source":["# what was the best year of sales\n","\n","dataset['year'] = pd.DatetimeIndex(dataset['timestamp']).year\n","\n","dataset.groupby('year')['rating'].count().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JW5JEz77hsC5"},"outputs":[],"source":["# what brand sold the most in 2015\n","\n","dataset_2015 = dataset[dataset['year'] == 2015]\n","\n","dataset_2015.groupby('brand')['rating'].count().sort_values(ascending=False).head(10).plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5rNjHPBDhsC5"},"outputs":[],"source":["# Mpow sold the most followed closely with Bose while the least sold was Eldhus."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"udj7xQ9GhsC5"},"outputs":[],"source":["# what product sold the most in 2016\n","\n","dataset[dataset['year'] == 2016].groupby('brand')['rating'].count().sort_values(ascending=False).head(10).plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9Xw4CvUhsC6"},"outputs":[],"source":["# the top 3 products sold in 2016 were Bose, Logitech & TaoTronics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-_6fUDJhsC6"},"outputs":[],"source":["# what product sold the most in 2017\n","\n","dataset[dataset['year'] == 2017].groupby('brand')['rating'].count().sort_values(ascending=False).head(10).plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-k0yAfaWhsC6"},"outputs":[],"source":["# the top 3 products sold in 2017 were Bose, Logitech and Mpow."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Uan0SufhsC7"},"outputs":[],"source":["# what product sold the most in 2018\n","\n","dataset[dataset['year'] == 2018].groupby('brand')['rating'].count().sort_values(ascending=False).head(10).plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qyk5IPxohsC7"},"outputs":[],"source":["# the top 3 products sold in 2018 were Bose, Mpow and Logitech."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzMd4iYVhsC7"},"outputs":[],"source":["# How much was made in sales in the year 2015\n","\n","dataset[dataset['year'] == 2015].groupby('year')['rating'].count().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bIttdjWehsC7"},"outputs":[],"source":["# We can see that the year 2015 had the best sales.\n","\n","# what was the best month of sales\n","\n","dataset['month'] = pd.DatetimeIndex(dataset['timestamp']).month\n","\n","dataset.groupby('month')['rating'].count().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"312RK3E4hsC8"},"outputs":[],"source":["# The month of January had the best sales."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAE0hW3bhsC8"},"outputs":[],"source":["# What product by brand name sold the most?\n","\n","\n","dataset.groupby('brand')['rating'].count().sort_values(ascending=False).head(10).plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-smXmL3BhsC8"},"outputs":[],"source":["# We can see that the brand name of Bose sold the most followed closely with Logitech."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Upa9ywYwhsC8"},"outputs":[],"source":["# What product by category sold the most?\n","\n","dataset.groupby('category')['rating'].count().sort_values(ascending=False).head(10).plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjpCzjd6hsC8"},"outputs":[],"source":["# We can see that the category of Headphones sold the most.\n","\n","# computers and accesories were sold the second most\n","\n","# camera & photo sold the third most followed by Accesories and supplies\n","\n","# the least sold category was Security and Surveillance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8ohpyl7hsC9"},"outputs":[],"source":["# What product by brand name sold the least?\n","\n","dataset.groupby('brand')['rating'].count().sort_values(ascending=True).head(10).plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32LNgmP4hsC9"},"outputs":[],"source":["# We can see that the brand name of Koolertron sold the least followed closely with DURAGADGET."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G_NJveoIhsC9"},"outputs":[],"source":["# What product by category sold the least?\n","\n","dataset.groupby('category')['rating'].count().sort_values(ascending=True).head(10).plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kplir10vhsC9"},"outputs":[],"source":["# We can see that the category of Security and Surveillance sold the least."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"StqNewmwhsC9"},"outputs":[],"source":["# category percentage sales\n","\n","dataset.groupby('category')['rating'].count().sort_values(ascending=False).head(10).plot(kind='pie')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2oe7Q7OShsDD"},"outputs":[],"source":["# brand percentage sales\n","\n","dataset.groupby('brand')['rating'].count().sort_values(ascending=False).head(10).plot(kind='pie')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Azp5bga7hsDE"},"outputs":[],"source":["# We can see that the brand name of Bose and Logitech had the most sales"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5FdWtjMhsDE"},"outputs":[],"source":["# conclusion of our analysis\n","\n","# We can see that the year 2015 had the best sales.\n","\n","# The month of January had the best sales.\n","\n","# We can see that the brands Bose and Logitech sold the most\n","\n","# We can see that the category of Headphones sold the most.\n","\n","# We can see that the brand name of EINCAR sold the least followed closely with DURAGADGET.\n","\n","# We can see that the category of Security and Surveillance sold the least."]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"05b71705b04c77cad66c5cedfdd779190a105974319382f7eac1b92ec6a4f5bf"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}